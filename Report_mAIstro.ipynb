{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranabilal09/Report-mAIstro/blob/main/Report_mAIstro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "id": "PSVF5n_wQRTI"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet langchain langchain-google-genai langgraph langgraph langgraph-sdk langsmith langchain-huggingface langgraph-cli tavily-python langchain-community langchain-core\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wAdbu1a9tOGh",
        "outputId": "282d27e6-b3f0-420b-83cf-1bfd56b561e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-jwsS81F9AVr"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily_api_key')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Gemini_Api_Key')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchai_api_key')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Report-mAIstro\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "w9iIhjJ48dE0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dataclasses import dataclass, field, fields\n",
        "from typing import Any, Optional\n",
        "\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "DEFAULT_REPORT_STRUCTURE = \"\"\"The report structure should focus on breaking-down the user-provided topic:\n",
        "\n",
        "1. Introduction (no research needed)\n",
        "   - Brief overview of the topic area\n",
        "\n",
        "2. Main Body Sections:\n",
        "   - Each section should focus on a sub-topic of the user-provided topic\n",
        "   - Include any key concepts and definitions\n",
        "   - Provide real-world examples or case studies where applicable\n",
        "\n",
        "3. Conclusion\n",
        "   - Aim for 1 structural element (either a list of table) that distills the main body sections\n",
        "   - Provide a concise summary of the report\"\"\"\n",
        "\n",
        "@dataclass(kw_only=True)\n",
        "class Configuration:\n",
        "    \"\"\"The configurable fields for the chatbot.\"\"\"\n",
        "    report_structure: str = DEFAULT_REPORT_STRUCTURE\n",
        "    number_of_queries: int = 2\n",
        "    tavily_topic: str = \"general\"\n",
        "    tavily_days: str = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_runnable_config(\n",
        "        cls, config: Optional[RunnableConfig] = None\n",
        "    ) -> \"Configuration\":\n",
        "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
        "        configurable = (\n",
        "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
        "        )\n",
        "        values: dict[str, Any] = {\n",
        "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
        "            for f in fields(cls)\n",
        "            if f.init\n",
        "        }\n",
        "        return cls(**{k: v for k, v in values.items() if v})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WAcZ95rc5BD4"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import operator\n",
        "from typing_extensions import TypedDict\n",
        "from typing import  Annotated, List, Optional, Literal\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from tavily import TavilyClient, AsyncTavilyClient\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.constants import Send\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langsmith import traceable\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# LLMs\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-8b\")\n",
        "llama = HuggingFaceEndpoint(model=\"meta-llama/Llama-3.2-1B\")\n",
        "\n",
        "# # ------------------------------------------------------------\n",
        "# Search\n",
        "\n",
        "tavily_client = TavilyClient()\n",
        "tavily_async_client = AsyncTavilyClient()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Schema\n",
        "\n",
        "class Section(BaseModel):\n",
        "    name: str = Field(\n",
        "        description=\"Name for this section of the report.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
        "    )\n",
        "    research: bool = Field(\n",
        "        description=\"Whether to perform web research for this section of the report.\"\n",
        "    )\n",
        "    content: str = Field(\n",
        "        description=\"The content of the section.\"\n",
        "    )\n",
        "\n",
        "class Sections(BaseModel):\n",
        "    sections: List[Section] = Field(\n",
        "        description=\"Sections of the report.\",\n",
        "    )\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    search_query: str = Field(None, description=\"Query for web search.\")\n",
        "\n",
        "class Queries(BaseModel):\n",
        "    queries: List[SearchQuery] = Field(\n",
        "        description=\"List of search queries.\",\n",
        "    )\n",
        "\n",
        "class ReportStateInput(TypedDict):\n",
        "    topic: str # Report topic\n",
        "\n",
        "class ReportStateOutput(TypedDict):\n",
        "    final_report: str # Final report\n",
        "\n",
        "class ReportState(TypedDict):\n",
        "    topic: str # Report topic\n",
        "    sections: list[Section] # List of report sections\n",
        "    completed_sections: Annotated[list, operator.add] # Send() API key\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    final_report: str # Final report\n",
        "\n",
        "class SectionState(TypedDict):\n",
        "    section: Section # Report section\n",
        "    search_queries: list[SearchQuery] # List of search queries\n",
        "    source_str: str # String of formatted source content from web search\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
        "\n",
        "class SectionOutputState(TypedDict):\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8yEviOQF81r_"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n",
        "    \"\"\"\n",
        "    Takes either a single search response or list of responses from Tavily API and formats them.\n",
        "    Limits the raw_content to approximately max_tokens_per_source.\n",
        "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
        "\n",
        "    Args:\n",
        "        search_response: Either:\n",
        "            - A dict with a 'results' key containing a list of search results\n",
        "            - A list of dicts, each containing search results\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted string with deduplicated sources\n",
        "    \"\"\"\n",
        "    # Convert input to list of results\n",
        "    if isinstance(search_response, dict):\n",
        "        sources_list = search_response['results']\n",
        "    elif isinstance(search_response, list):\n",
        "        sources_list = []\n",
        "        for response in search_response:\n",
        "            if isinstance(response, dict) and 'results' in response:\n",
        "                sources_list.extend(response['results'])\n",
        "            else:\n",
        "                sources_list.extend(response)\n",
        "    else:\n",
        "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
        "\n",
        "    # Deduplicate by URL\n",
        "    unique_sources = {}\n",
        "    for source in sources_list:\n",
        "        if source['url'] not in unique_sources:\n",
        "            unique_sources[source['url']] = source\n",
        "\n",
        "    # Format output\n",
        "    formatted_text = \"Sources:\\n\\n\"\n",
        "    for i, source in enumerate(unique_sources.values(), 1):\n",
        "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
        "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
        "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
        "        if include_raw_content:\n",
        "            # Using rough estimate of 4 characters per token\n",
        "            char_limit = max_tokens_per_source * 4\n",
        "            # Handle None raw_content\n",
        "            raw_content = source.get('raw_content', '')\n",
        "            if raw_content is None:\n",
        "                raw_content = ''\n",
        "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
        "            if len(raw_content) > char_limit:\n",
        "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
        "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
        "\n",
        "    return formatted_text.strip()\n",
        "\n",
        "def format_sections(sections: list[Section]) -> str:\n",
        "    \"\"\" Format a list of sections into a string \"\"\"\n",
        "    formatted_str = \"\"\n",
        "    for idx, section in enumerate(sections, 1):\n",
        "        formatted_str += f\"\"\"\n",
        "{'='*60}\n",
        "Section {idx}: {section.name}\n",
        "{'='*60}\n",
        "Description:\n",
        "{section.description}\n",
        "Requires Research:\n",
        "{section.research}\n",
        "\n",
        "Content:\n",
        "{section.content if section.content else '[Not yet written]'}\n",
        "\n",
        "\"\"\"\n",
        "    return formatted_str\n",
        "\n",
        "@traceable\n",
        "def tavily_search(query):\n",
        "    \"\"\" Search the web using the Tavily API.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query to execute\n",
        "\n",
        "    Returns:\n",
        "        dict: Tavily search response containing:\n",
        "            - results (list): List of search result dictionaries, each containing:\n",
        "                - title (str): Title of the search result\n",
        "                - url (str): URL of the search result\n",
        "                - content (str): Snippet/summary of the content\n",
        "                - raw_content (str): Full content of the page if available\"\"\"\n",
        "\n",
        "    return tavily_client.search(query,\n",
        "                         max_results=5,\n",
        "                         include_raw_content=True)\n",
        "\n",
        "@traceable\n",
        "async def tavily_search_async(search_queries, tavily_topic, tavily_days):\n",
        "    \"\"\"\n",
        "    Performs concurrent web searches using the Tavily API.\n",
        "\n",
        "    Args:\n",
        "        search_queries (List[SearchQuery]): List of search queries to process\n",
        "        tavily_topic (str): Type of search to perform ('news' or 'general')\n",
        "        tavily_days (int): Number of days to look back for news articles (only used when tavily_topic='news')\n",
        "\n",
        "    Returns:\n",
        "        List[dict]: List of search results from Tavily API, one per query\n",
        "\n",
        "    Note:\n",
        "        For news searches, each result will include articles from the last `tavily_days` days.\n",
        "        For general searches, the time range is unrestricted.\n",
        "    \"\"\"\n",
        "\n",
        "    search_tasks = []\n",
        "    for query in search_queries:\n",
        "        if tavily_topic == \"news\":\n",
        "            search_tasks.append(\n",
        "                tavily_async_client.search(\n",
        "                    query,\n",
        "                    max_results=5,\n",
        "                    include_raw_content=True,\n",
        "                    topic=\"news\",\n",
        "                    days=tavily_days\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            search_tasks.append(\n",
        "                tavily_async_client.search(\n",
        "                    query,\n",
        "                    max_results=5,\n",
        "                    include_raw_content=True,\n",
        "                    topic=\"general\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # Execute all searches concurrently\n",
        "    search_docs = await asyncio.gather(*search_tasks)\n",
        "\n",
        "    return search_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "O6OmzKNJDogO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prompt to generate a search query to help with planning the report outline\n",
        "report_planner_query_writer_instructions=\"\"\"You are an expert technical writer, helping to plan a report.\n",
        "\n",
        "The report will be focused on the following topic:\n",
        "\n",
        "{topic}\n",
        "\n",
        "The report structure will follow these guidelines:\n",
        "\n",
        "{report_organization}\n",
        "\n",
        "Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information for planning the report sections.\n",
        "\n",
        "The query should:\n",
        "\n",
        "1. Be related to the topic\n",
        "2. Help satisfy the requirements specified in the report organization\n",
        "\n",
        "Make the query specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.\"\"\"\n",
        "\n",
        "# Prompt generating the report outline\n",
        "report_planner_instructions=\"\"\"You are an expert technical writer, helping to plan a report.\n",
        "\n",
        "Your goal is to generate the outline of the sections of the report.\n",
        "\n",
        "The overall topic of the report is:\n",
        "\n",
        "{topic}\n",
        "\n",
        "The report should follow this organization:\n",
        "\n",
        "{report_organization}\n",
        "\n",
        "You should reflect on this information to plan the sections of the report:\n",
        "\n",
        "{context}\n",
        "\n",
        "Now, generate the sections of the report. Each section must have the following given instructions.\n",
        "**Your response must be a valid JSON object with a 'sections' field containing a list of sections. Each section must have: name, description, research, and content fields. All these fields are required. For example:\n",
        "- Name - Name for this section of the report.\n",
        "- Description - Brief overview of the main topics and concepts to be covered in this section.\n",
        "- Research - Whether to perform web research for this section of the report.\n",
        "- Content - The content of the section, which you will leave blank for now.\n",
        "\n",
        "Consider which sections require web research. For example, introduction and conclusion will not require research because they will distill information from other parts of the report.\n",
        "\"\"\"\n",
        "# Query writer instructions\n",
        "query_writer_instructions=\"\"\"Your goal is to generate targeted web search queries that will gather comprehensive information for writing a technical report section.\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "When generating {number_of_queries} search queries, ensure they:\n",
        "1. Cover different aspects of the topic (e.g., core features, real-world applications, technical architecture)\n",
        "2. Include specific technical terms related to the topic\n",
        "3. Target recent information by including year markers where relevant (e.g., \"2024\")\n",
        "4. Look for comparisons or differentiators from similar technologies/approaches\n",
        "5. Search for both official documentation and practical implementation examples\n",
        "\n",
        "Your queries should be:\n",
        "- Specific enough to avoid generic results\n",
        "- Technical enough to capture detailed implementation information\n",
        "- Diverse enough to cover all aspects of the section plan\n",
        "- Focused on authoritative sources (documentation, technical blogs, academic papers)\"\"\"\n",
        "\n",
        "# Section writer instructions\n",
        "section_writer_instructions = \"\"\"You are an expert technical writer crafting one section of a technical report.\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "Guidelines for writing:\n",
        "\n",
        "1. Technical Accuracy:\n",
        "- Include specific version numbers\n",
        "- Reference concrete metrics/benchmarks\n",
        "- Cite official documentation\n",
        "- Use technical terminology precisely\n",
        "\n",
        "2. Length and Style:\n",
        "- Strict 150-200 word limit\n",
        "- No marketing language\n",
        "- Technical focus\n",
        "- Write in simple, clear language\n",
        "- Start with your most important insight in **bold**\n",
        "- Use short paragraphs (2-3 sentences max)\n",
        "\n",
        "3. Structure:\n",
        "- Use ## for section title (Markdown format)\n",
        "- Only use ONE structural element IF it helps clarify your point:\n",
        "  * Either a focused table comparing 2-3 key items (using Markdown table syntax)\n",
        "  * Or a short list (3-5 items) using proper Markdown list syntax:\n",
        "    - Use `*` or `-` for unordered lists\n",
        "    - Use `1.` for ordered lists\n",
        "    - Ensure proper indentation and spacing\n",
        "- End with ### Sources that references the below source material formatted as:\n",
        "  * List each source with title, date, and URL\n",
        "  * Format: `- Title : URL`\n",
        "\n",
        "3. Writing Approach:\n",
        "- Include at least one specific example or case study\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- No preamble prior to creating the section content\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Use this source material to help write the section:\n",
        "{context}\n",
        "\n",
        "5. Quality Checks:\n",
        "- Exactly 150-200 words (excluding title and sources)\n",
        "- Careful use of only ONE structural element (table or list) and only if it helps clarify your point\n",
        "- One specific example / case study\n",
        "- Starts with bold insight\n",
        "- No preamble prior to creating the section content\n",
        "- Sources cited at end\"\"\"\n",
        "\n",
        "final_section_writer_instructions=\"\"\"You are an expert technical writer crafting a section that synthesizes information from the rest of the report.\n",
        "\n",
        "Section to write:\n",
        "{section_topic}\n",
        "\n",
        "Available report content:\n",
        "{context}\n",
        "\n",
        "1. Section-Specific Approach:\n",
        "\n",
        "For Introduction:\n",
        "- Use # for report title (Markdown format)\n",
        "- 50-100 word limit\n",
        "- Write in simple and clear language\n",
        "- Focus on the core motivation for the report in 1-2 paragraphs\n",
        "- Use a clear narrative arc to introduce the report\n",
        "- Include NO structural elements (no lists or tables)\n",
        "- No sources section needed\n",
        "\n",
        "For Conclusion/Summary:\n",
        "- Use ## for section title (Markdown format)\n",
        "- 100-150 word limit\n",
        "- For comparative reports:\n",
        "    * Must include a focused comparison table using Markdown table syntax\n",
        "    * Table should distill insights from the report\n",
        "    * Keep table entries clear and concise\n",
        "- For non-comparative reports:\n",
        "    * Only use ONE structural element IF it helps distill the points made in the report:\n",
        "    * Either a focused table comparing items present in the report (using Markdown table syntax)\n",
        "    * Or a short list using proper Markdown list syntax:\n",
        "      - Use `*` or `-` for unordered lists\n",
        "      - Use `1.` for ordered lists\n",
        "      - Ensure proper indentation and spacing\n",
        "- End with specific next steps or implications\n",
        "- No sources section needed\n",
        "\n",
        "3. Writing Approach:\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Quality Checks:\n",
        "- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section\n",
        "- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section\n",
        "- Markdown format\n",
        "- Do not include word count or any preamble in your response\"\"\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Graph nodes\n",
        "\n",
        "async def generate_report_plan(state: ReportState, config: RunnableConfig):\n",
        "    \"\"\" Generate the report plan \"\"\"\n",
        "\n",
        "    # Inputs\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Get configuration\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    report_structure = configurable.report_structure\n",
        "    number_of_queries = configurable.number_of_queries\n",
        "    tavily_topic = configurable.tavily_topic\n",
        "    tavily_days = configurable.tavily_days\n",
        "\n",
        "    # Convert JSON object to string if necessary\n",
        "    if isinstance(report_structure, dict):\n",
        "        report_structure = str(report_structure)\n",
        "\n",
        "    # Generate search query\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)\n",
        "\n",
        "    # Generate queries\n",
        "    results = structured_llm.invoke([SystemMessage(content=system_instructions_query)]+[HumanMessage(content=\"Generate search queries that will help with planning the sections of the report.\")])\n",
        "\n",
        "    # Web search\n",
        "    query_list = [query.search_query for query in results.queries]\n",
        "\n",
        "    # Search web\n",
        "    search_docs = await tavily_search_async(query_list, tavily_topic, tavily_days)\n",
        "\n",
        "    # Deduplicate and format sources\n",
        "    source_str = deduplicate_and_format_sources(search_docs, max_tokens_per_source=1000, include_raw_content=False)\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str)\n",
        "\n",
        "    # Generate sections\n",
        "    structured_llm = llm.with_structured_output(Sections)\n",
        "    report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections)]+[HumanMessage(content=\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.\")])\n",
        "\n",
        "    return {\"sections\": report_sections.sections}\n",
        "\n",
        "def generate_queries(state: SectionState, config: RunnableConfig):\n",
        "    \"\"\" Generate search queries for a report section \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "\n",
        "    # Get configuration\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    number_of_queries = configurable.number_of_queries\n",
        "\n",
        "    # Generate queries\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = query_writer_instructions.format(section_topic=section.description, number_of_queries=number_of_queries)\n",
        "\n",
        "    # Generate queries\n",
        "    queries = structured_llm.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content=\"Generate search queries on the provided topic.\")])\n",
        "\n",
        "    return {\"search_queries\": queries.queries}\n",
        "\n",
        "async def search_web(state: SectionState, config: RunnableConfig):\n",
        "    \"\"\" Search the web for each query, then return a list of raw sources and a formatted string of sources.\"\"\"\n",
        "\n",
        "    # Get state\n",
        "    search_queries = state[\"search_queries\"]\n",
        "\n",
        "    # Get configuration\n",
        "    configurable = Configuration.from_runnable_config(config)\n",
        "    tavily_topic = configurable.tavily_topic\n",
        "    tavily_days = configurable.tavily_days\n",
        "\n",
        "    # Web search\n",
        "    query_list = [query.search_query for query in search_queries]\n",
        "    search_docs = await tavily_search_async(query_list, tavily_topic, tavily_days)\n",
        "\n",
        "    # Deduplicate and format sources\n",
        "    source_str = deduplicate_and_format_sources(search_docs, max_tokens_per_source=5000, include_raw_content=True)\n",
        "\n",
        "    return {\"source_str\": source_str}\n",
        "\n",
        "def write_section(state: SectionState):\n",
        "    \"\"\" Write a section of the report \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    source_str = state[\"source_str\"]\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = section_writer_instructions.format(section_title=section.name, section_topic=section.description, context=source_str)\n",
        "\n",
        "    # Generate section\n",
        "    section_content = llama.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content=\"Generate a report section based on the provided sources.\")])\n",
        "\n",
        "    # Write content to the section object\n",
        "    section.content = section_content.content\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add nodes and edges\n",
        "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
        "section_builder.add_node(\"generate_queries\", generate_queries)\n",
        "section_builder.add_node(\"search_web\", search_web)\n",
        "section_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "section_builder.add_edge(START, \"generate_queries\")\n",
        "section_builder.add_edge(\"generate_queries\", \"search_web\")\n",
        "section_builder.add_edge(\"search_web\", \"write_section\")\n",
        "section_builder.add_edge(\"write_section\", END)\n",
        "\n",
        "def initiate_section_writing(state: ReportState):\n",
        "    \"\"\" This is the \"map\" step when we kick off web research for some sections of the report \"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that require research\n",
        "    return [\n",
        "        Send(\"build_section_with_web_research\", {\"section\": s})\n",
        "        for s in state[\"sections\"]\n",
        "        if s.research\n",
        "    ]\n",
        "\n",
        "def write_final_sections(state: SectionState):\n",
        "    \"\"\" Write final sections of the report, which do not require web search and use the completed sections as context \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    completed_report_sections = state[\"report_sections_from_research\"]\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = final_section_writer_instructions.format(section_title=section.name, section_topic=section.description, context=completed_report_sections)\n",
        "\n",
        "    # Generate section\n",
        "    section_content = llama.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content=\"Generate a report section based on the provided sources.\")])\n",
        "\n",
        "    # Write content to section\n",
        "    section.content = section_content.content\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}\n",
        "\n",
        "def gather_completed_sections(state: ReportState):\n",
        "    \"\"\" Gather completed sections from research and format them as context for writing the final sections \"\"\"\n",
        "\n",
        "    # List of completed sections\n",
        "    completed_sections = state[\"completed_sections\"]\n",
        "\n",
        "    # Format completed section to str to use as context for final sections\n",
        "    completed_report_sections = format_sections(completed_sections)\n",
        "\n",
        "    return {\"report_sections_from_research\": completed_report_sections}\n",
        "\n",
        "def initiate_final_section_writing(state: ReportState):\n",
        "    \"\"\" Write any final sections using the Send API to parallelize the process \"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
        "    return [\n",
        "        Send(\"write_final_sections\", {\"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]})\n",
        "        for s in state[\"sections\"]\n",
        "        if not s.research\n",
        "    ]\n",
        "\n",
        "def compile_final_report(state: ReportState):\n",
        "    \"\"\" Compile the final report \"\"\"\n",
        "\n",
        "    # Get sections\n",
        "    sections = state[\"sections\"]\n",
        "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
        "\n",
        "    # Update sections with completed content while maintaining original order\n",
        "    for section in sections:\n",
        "        section.content = completed_sections[section.name]\n",
        "\n",
        "    # Compile final report\n",
        "    all_sections = \"\\n\\n\".join([s.content for s in sections])\n",
        "\n",
        "    return {\"final_report\": all_sections}\n",
        "\n",
        "# Add nodes and edges\n",
        "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
        "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
        "builder.add_node(\"build_section_with_web_research\", section_builder.compile())\n",
        "builder.add_node(\"gather_completed_sections\", gather_completed_sections)\n",
        "builder.add_node(\"write_final_sections\", write_final_sections)\n",
        "builder.add_node(\"compile_final_report\", compile_final_report)\n",
        "builder.add_edge(START, \"generate_report_plan\")\n",
        "builder.add_conditional_edges(\"generate_report_plan\", initiate_section_writing, [\"build_section_with_web_research\"])\n",
        "builder.add_edge(\"build_section_with_web_research\", \"gather_completed_sections\")\n",
        "builder.add_conditional_edges(\"gather_completed_sections\", initiate_final_section_writing, [\"write_final_sections\"])\n",
        "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
        "builder.add_edge(\"compile_final_report\", END)\n",
        "\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "tFsIrn0gqVRd"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBBolF1ND0fZSZZfe5YtOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}